"""
MCP Heuristics-based Retrieval (–±–µ–∑ LLM)

–ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è MCP retrieval —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —ç–≤—Ä–∏—Å—Ç–∏–∫ –≤–º–µ—Å—Ç–æ LLM.
–ù–µ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (OpenAI, Anthropic, Ollama).
"""

from __future__ import annotations

import logging
from pathlib import Path
from typing import Any, Dict, List, Optional, Set

from .mcp_retrieval import LoCoBenchMCPServer

logger = logging.getLogger(__name__)


def retrieve_with_mcp_heuristics(
    context_files: Dict[str, str],
    task_prompt: str,
    task_category: str,
    project_dir: Path,
    max_context_tokens: Optional[int] = None,
    top_percent: Optional[float] = None,
) -> str:
    """
    MCP-based retrieval —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —ç–≤—Ä–∏—Å—Ç–∏–∫ (–±–µ–∑ LLM).
    
    –≠—Ç–æ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è, –∫–æ—Ç–æ—Ä–∞—è:
    1. –°–æ–∑–¥–∞–µ—Ç MCP Server —Å tools –¥–ª—è —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
    2. –í—ã–ø–æ–ª–Ω—è–µ—Ç –≤—Å–µ tools —Å –±–∞–∑–æ–≤—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    3. –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ—Ç
    4. –§–æ—Ä–º–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    
    Args:
        context_files: –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞
        task_prompt: –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
        task_category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è –∑–∞–¥–∞—á–∏
        project_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞
    
    Returns:
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏
    """
    logger.info(f"üîß Using MCP heuristics-based retrieval for category: {task_category}")
    
    # –ï—Å–ª–∏ context_files –ø—É—Å—Ç–æ–π, –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª—ã –∏–∑ project_dir
    # –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—É—Ç–∏ –∏–∑ scenario –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
    if not context_files:
        if project_dir and project_dir.exists():
            logger.info(f"üìÅ context_files –ø—É—Å—Ç–æ–π, –∑–∞–≥—Ä—É–∂–∞—é —Ñ–∞–π–ª—ã –∏–∑ project_dir: {project_dir}")
            try:
                from ..retrieval import _collect_project_code_files
                
                project_files = _collect_project_code_files(project_dir)
                context_files = {
                    file_info["path"]: file_info["content"]
                    for file_info in project_files
                }
                logger.info(f"‚úÖ Loaded {len(context_files)} files from project directory")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Failed to load files from project_dir: {e}")
                context_files = {}
        else:
            logger.warning(f"‚ö†Ô∏è context_files –ø—É—Å—Ç–æ–π –∏ project_dir –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {project_dir}")
            return ""
    
    if not context_files:
        logger.warning("‚ö†Ô∏è No context files available for MCP retrieval")
        return ""
    
    # –°–æ–∑–¥–∞—Ç—å MCP —Å–µ—Ä–≤–µ—Ä
    server = LoCoBenchMCPServer(
        project_dir=project_dir,
        task_category=task_category,
        context_files=context_files,
        task_prompt=task_prompt,
    )
    
    logger.info(f"üìã Created MCP server with {len(server.tools)} tools, {len(context_files)} files available")
    
    # –í—ã–ø–æ–ª–Ω–∏—Ç—å –≤—Å–µ tools —Å –±–∞–∑–æ–≤—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    all_results = []
    
    for tool in server.tools:
        try:
            # –ü–æ–ª—É—á–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã tool –∏–∑ –µ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
            tool_params_def = tool.parameters  # Dict —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            tool_params = {}
            
            # –ò–∑–≤–ª–µ—á—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–¥–∞—á–∏
            task_words = set(task_prompt.lower().split())
            keywords = " ".join(sorted(task_words)[:15])  # –ü–µ—Ä–≤—ã–µ 15 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤
            
            # –ó–∞–ø–æ–ª–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è tool –∏ —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
            for param_name in tool_params_def.keys():
                if param_name == "keywords":
                    # –î–æ–±–∞–≤–∏—Ç—å keywords —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                    base_keywords = keywords
                    if "security" in task_category.lower():
                        base_keywords += " security auth validate sanitize"
                    elif "architectural" in task_category.lower():
                        base_keywords += " architecture design pattern component"
                    elif "comprehension" in task_category.lower():
                        base_keywords += " trace flow execution call"
                    tool_params[param_name] = base_keywords
                
                elif param_name == "file_patterns":
                    if "security" in task_category.lower():
                        tool_params[param_name] = "auth security validate"
                    else:
                        tool_params[param_name] = ""
                
                elif param_name == "component_types":
                    if "architectural" in task_category.lower():
                        tool_params[param_name] = "interface abstract pattern"
                    else:
                        tool_params[param_name] = ""
                
                elif param_name == "feature_type":
                    # –ò–∑–≤–ª–µ—á—å —Ç–∏–ø —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ –∑–∞–¥–∞—á–∏
                    tool_params[param_name] = keywords.split()[0] if keywords else ""
                
                elif param_name == "similar_features":
                    tool_params[param_name] = keywords
                
                elif param_name == "feature_requirements":
                    tool_params[param_name] = task_prompt[:200]  # –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤
                
                elif param_name == "feature_domain":
                    # –ò–∑–≤–ª–µ—á—å –¥–æ–º–µ–Ω –∏–∑ –ø–µ—Ä–≤—ã—Ö —Å–ª–æ–≤ –∑–∞–¥–∞—á–∏
                    tool_params[param_name] = keywords.split()[0] if keywords else ""
                
                elif param_name == "function_name":
                    # –ü–æ–ø—ã—Ç–∞—Ç—å—Å—è –Ω–∞–π—Ç–∏ –∏–º—è —Ñ—É–Ω–∫—Ü–∏–∏ –≤ –∑–∞–¥–∞—á–µ
                    import re
                    func_match = re.search(r'\b(function|def|method)\s+(\w+)', task_prompt, re.IGNORECASE)
                    tool_params[param_name] = func_match.group(2) if func_match else ""
                
                elif param_name == "entry_point":
                    tool_params[param_name] = "main"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
                
                elif param_name == "target_function":
                    # –ü–æ–ø—ã—Ç–∞—Ç—å—Å—è –Ω–∞–π—Ç–∏ —Ü–µ–ª–µ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é
                    import re
                    func_match = re.search(r'\b(function|def|method)\s+(\w+)', task_prompt, re.IGNORECASE)
                    tool_params[param_name] = func_match.group(2) if func_match else ""
                
                elif param_name == "data_sources" or param_name == "data_sinks":
                    tool_params[param_name] = ""
                
                elif param_name == "error_message" or param_name == "error_location":
                    tool_params[param_name] = ""
                
                elif param_name == "error_type":
                    tool_params[param_name] = ""
                
                elif param_name == "problem_area":
                    tool_params[param_name] = keywords
                
                elif param_name == "refactoring_goal":
                    tool_params[param_name] = task_prompt[:200]
                
                elif param_name == "target_files":
                    tool_params[param_name] = ""
                
                elif param_name == "components":
                    tool_params[param_name] = ""
                
                elif param_name == "state_type":
                    tool_params[param_name] = ""
                
                elif param_name == "input_sources":
                    tool_params[param_name] = "API forms files"
                
                elif param_name == "entry_points" or param_name == "sensitive_operations":
                    tool_params[param_name] = ""
                
                else:
                    # –î–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –∏–ª–∏ keywords
                    tool_params[param_name] = keywords if "keyword" in param_name.lower() else ""
            
            # –í—ã–ø–æ–ª–Ω–∏—Ç—å tool —Ç–æ–ª—å–∫–æ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –æ–Ω –ø—Ä–∏–Ω–∏–º–∞–µ—Ç
            results = tool.execute(**tool_params)
            all_results.extend(results)
            
            logger.debug(f"‚úÖ Tool '{tool.name}': found {len(results)} files")
            
        except TypeError as e:
            # –û—à–∏–±–∫–∞ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ - –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            logger.debug(f"‚ö†Ô∏è Tool '{tool.name}' parameter mismatch, trying minimal params: {e}")
            try:
                # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –±–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–ª–∏ —Å –ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
                minimal_params = {param: "" for param in tool.parameters.keys()}
                results = tool.execute(**minimal_params)
                all_results.extend(results)
                logger.debug(f"‚úÖ Tool '{tool.name}': found {len(results)} files (minimal params)")
            except Exception as e2:
                logger.warning(f"‚ö†Ô∏è Tool '{tool.name}' failed even with minimal params: {e2}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Tool '{tool.name}' failed: {e}")
            # –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å –¥—Ä—É–≥–∏–º–∏ tools
    
    if not all_results:
        logger.warning("‚ö†Ô∏è No files found by any tool, returning empty result")
        return ""
    
    # –î–µ–¥—É–ø–ª–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –ø–æ –ø—É—Ç–∏ —Ñ–∞–π–ª–∞
    seen_paths: Set[str] = set()
    unique_results: List[Dict[str, Any]] = []
    
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ relevance_score –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
    sorted_results = sorted(
        all_results,
        key=lambda x: x.get("relevance_score", 0.0),
        reverse=True
    )
    
    # –ü—Ä–∏–º–µ–Ω–∏—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤
    max_files = None
    if top_percent and context_files:
        max_files = max(1, int(len(context_files) * top_percent))
        logger.debug(f"üìä Limiting to top {max_files} files ({top_percent*100:.1f}% of {len(context_files)} files)")
    
    for result in sorted_results:
        path = result.get("path", "")
        if path and path not in seen_paths:
            seen_paths.add(path)
            unique_results.append(result)
            server.selected_files.add(path)
            
            # –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ
            if max_files and len(unique_results) >= max_files:
                logger.debug(f"üìä Reached file limit: {max_files} files")
                break
    
    logger.info(f"‚úÖ Selected {len(unique_results)} unique files from {len(all_results)} total results")
    
    # –ü—Ä–∏–º–µ–Ω–∏—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    # max_context_tokens —É–∂–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—Ç—Å—è –∫–∞–∫ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ (—Å–º. _apply_length_budget –≤ retrieval.py)
    if max_context_tokens:
        max_chars = max_context_tokens  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–ø—Ä—è–º—É—é –∫–∞–∫ —Å–∏–º–≤–æ–ª—ã
        total_chars = 0
        filtered_results = []
        
        for result in unique_results:
            content = result.get("content", "")
            content_length = len(content)
            
            if total_chars + content_length <= max_chars:
                filtered_results.append(result)
                total_chars += content_length
            else:
                # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥–æ–±–∞–≤–∏—Ç—å —á–∞—Å—Ç–∏—á–Ω–æ, –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π
                remaining = max_chars - total_chars
                if remaining > 1000:  # –ú–∏–Ω–∏–º—É–º 1000 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                    # –û–±—Ä–µ–∑–∞—Ç—å —Ñ–∞–π–ª –¥–æ –æ—Å—Ç–∞–≤—à–µ–≥–æ—Å—è –ª–∏–º–∏—Ç–∞
                    result_copy = result.copy()
                    result_copy["content"] = content[:remaining] + "\n... [truncated]"
                    filtered_results.append(result_copy)
                    total_chars = max_chars
                break
        
        if len(filtered_results) < len(unique_results):
            logger.info(
                f"üìä Trimmed from {len(unique_results)} to {len(filtered_results)} files "
                f"({total_chars:,} chars, limit: {max_chars:,} chars)"
            )
            unique_results = filtered_results
            server.selected_files = {r.get("path", "") for r in filtered_results}
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    result = server.format_selected_context()
    
    if result:
        logger.info(f"‚úÖ MCP heuristics retrieval returned {len(result)} characters")
    else:
        logger.warning("‚ö†Ô∏è MCP heuristics retrieval returned empty result")
    
    return result


def retrieve_with_mcp_simple(
    context_files: Dict[str, str],
    task_prompt: str,
    task_category: str,
    project_dir: Path,
    max_files: int = 10,
) -> str:
    """
    –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è MCP retrieval —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤.
    
    Args:
        context_files: –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞
        task_prompt: –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
        task_category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è –∑–∞–¥–∞—á–∏
        project_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞
        max_files: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞
    
    Returns:
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏
    """
    result = retrieve_with_mcp_heuristics(
        context_files=context_files,
        task_prompt=task_prompt,
        task_category=task_category,
        project_dir=project_dir,
    )
    
    # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π, –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤
    if result and max_files > 0:
        lines = result.split("\n")
        file_headers = []
        current_file = []
        files = []
        
        for line in lines:
            if line.startswith("### "):
                if current_file:
                    files.append("\n".join(current_file))
                current_file = [line]
                file_headers.append(line)
            else:
                current_file.append(line)
        
        if current_file:
            files.append("\n".join(current_file))
        
        if len(files) > max_files:
            logger.info(f"üìä Limiting results from {len(files)} to {max_files} files")
            result = "\n\n".join(files[:max_files])
    
    return result
