"""
MCP Tool for LoCoBench Scenario Filtering

This module provides an MCP tool that uses ChatOpenAI with AgentExecutor
to intelligently select relevant scenarios from files based on difficulty
and supported languages.
"""

import json
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional

# LangChain imports - optional, only needed for LLM-based filtering
# We'll import lazily to avoid import-time errors
_LANGCHAIN_AVAILABLE = False
_ChatOpenAI = None
_ChatPromptTemplate = None
_MessagesPlaceholder = None
_tool = None
_AgentExecutor = None
_create_openai_tools_agent = None

def _try_import_langchain():
    """Try to import LangChain components, handling version differences"""
    global _LANGCHAIN_AVAILABLE, _ChatOpenAI, _ChatPromptTemplate, _MessagesPlaceholder
    global _tool, _AgentExecutor, _create_openai_tools_agent
    
    if _LANGCHAIN_AVAILABLE:
        return True
    
    try:
        from langchain_openai import ChatOpenAI as _ChatOpenAI_impl
        from langchain_core.prompts import ChatPromptTemplate as _ChatPromptTemplate_impl
        from langchain_core.prompts import MessagesPlaceholder as _MessagesPlaceholder_impl
        from langchain_core.tools import tool as _tool_impl
        
        _ChatOpenAI = _ChatOpenAI_impl
        _ChatPromptTemplate = _ChatPromptTemplate_impl
        _MessagesPlaceholder = _MessagesPlaceholder_impl
        _tool = _tool_impl
        
        # Try to import agents
        try:
            from langchain.agents import AgentExecutor as _AgentExecutor_impl, create_openai_tools_agent as _create_openai_tools_agent_impl
            _AgentExecutor = _AgentExecutor_impl
            _create_openai_tools_agent = _create_openai_tools_agent_impl
            _LANGCHAIN_AVAILABLE = True
            return True
        except (ImportError, ModuleNotFoundError) as e:
            # LangChain 1.0+ might have different structure or missing dependencies
            logger.debug(f"Could not import LangChain agents: {e}")
            return False
            
    except (ImportError, ModuleNotFoundError) as e:
        logger.debug(f"LangChain not available: {e}")
        return False

from .core.config import Config

logger = logging.getLogger(__name__)


class LoCoBenchScenarioFilter:
    """MCP tool for filtering LoCoBench scenarios using LLM-based selection"""
    
    def __init__(self, config: Config, base_url: str = None, api_key: str = None, model: str = None):
        """
        Initialize the scenario filter
        
        Args:
            config: LoCoBench configuration object
            base_url: Base URL for the OpenAI-compatible API (defaults to config.mcp_filter.base_url)
            api_key: API key for authentication (defaults to config.mcp_filter.api_key)
            model: Model name for the filter agent (defaults to config.mcp_filter.model)
        """
        self.config = config
        
        # Use config values as defaults
        self.base_url = base_url or config.mcp_filter.base_url
        self.api_key = api_key or config.mcp_filter.api_key
        model_name = model or config.mcp_filter.model
        
        # Initialize LLM model and agent only if LangChain is available and LLM selection is enabled
        self.agent_executor = None
        if config.mcp_filter.use_llm_selection:
            # Try to import LangChain lazily
            if _try_import_langchain():
                try:
                    # Initialize the LLM model
                    self.model = _ChatOpenAI(
                        model=model_name,
                        temperature=0.0,
                        base_url=self.base_url,
                        api_key=self.api_key,
                        streaming=True,
                        timeout=30.0
                    )
                    
                    # Create tools for the agent
                    self.tools = self._create_tools()
                    
                    # Bind tools to model
                    self.model_with_tools = self.model.bind_tools(self.tools)
                    
                    # Create agent prompt
                    self.prompt = _ChatPromptTemplate.from_messages([
                        ("system", """You are an expert at analyzing and filtering code evaluation scenarios.
Your task is to help select relevant scenarios from a collection based on:
1. Difficulty level (easy, medium, hard, expert)
2. Programming language support
3. Task category relevance

When analyzing scenarios, consider:
- The scenario's difficulty level
- The programming language used
- The task category and its requirements
- The context size and complexity
- The actual code files referenced in context_files

You can:
- Read scenario files using read_scenario_file
- Read actual code files using read_code_file (requires scenario_id and context_file path)
- Read all context files for a scenario using read_scenario_context_files
- Extract metadata using get_scenario_metadata
- Filter scenarios using filter_by_difficulty and filter_by_language

The scenario ID (e.g., "c_api_gateway_easy_009_bug_investigation_expert_01") contains:
- Language prefix (c, cpp, py, etc.)
- Project directory name (c_api_gateway_easy_009)
- Task category (bug_investigation)
- Difficulty (expert)

Code files are located at: {generated_dir}/{project_dir}/{context_file}
where context_file comes from the scenario's context_files array.

Provide clear reasoning for your selections."""),
                        ("user", "{input}"),
                        _MessagesPlaceholder(variable_name="agent_scratchpad"),
                    ])
                    
                    # Create agent
                    agent = _create_openai_tools_agent(self.model_with_tools, self.tools, self.prompt)
                    
                    # Create agent executor
                    self.agent_executor = _AgentExecutor(
                        agent=agent,
                        tools=self.tools,
                        verbose=True
                    )
                except Exception as e:
                    logger.warning(f"Failed to initialize LangChain agent: {e}. LLM-based filtering will be disabled.")
                    self.agent_executor = None
            else:
                logger.info("LangChain not available. LLM-based filtering will be disabled.")
                self.model = None
                self.tools = []
        else:
            self.model = None
            self.tools = []
            logger.info("LangChain agent not initialized. Using basic filtering only.")
    
    def _extract_project_dir_from_id(self, scenario_id: str) -> str:
        """Extract project directory name from scenario ID.
        
        Example: "c_api_gateway_easy_009_bug_investigation_expert_01" -> "c_api_gateway_easy_009"
        
        Args:
            scenario_id: Scenario ID string
            
        Returns:
            Project directory name
        """
        if not scenario_id:
            return ""
        
        # Split by underscore
        parts = scenario_id.split('_')
        
        # The project directory is typically the first few parts before task_category
        # Common pattern: {lang}_{project_name}_{complexity}_{number}_{task_category}_{difficulty}_{instance}
        # We want: {lang}_{project_name}_{complexity}_{number}
        
        # Find where task_category starts (common task categories)
        task_categories = [
            'architectural_understanding', 'cross_file_refactoring', 'feature_implementation',
            'bug_investigation', 'multi_session_development', 'code_comprehension',
            'integration_testing', 'security_analysis'
        ]
        
        # Try to find task category in the parts
        project_parts = []
        for i, part in enumerate(parts):
            # Check if this part or next part starts a task category
            if part in task_categories or (i < len(parts) - 1 and f"{part}_{parts[i+1]}" in task_categories):
                break
            project_parts.append(part)
        
        # If we didn't find a task category, take first 4 parts as fallback
        if not project_parts or len(project_parts) < 2:
            project_parts = parts[:4] if len(parts) >= 4 else parts
        
        return '_'.join(project_parts)
    
    def _get_code_file_path(self, scenario_id: str, context_file: str) -> Path:
        """Get full path to a code file from scenario ID and context file path.
        
        Args:
            scenario_id: Scenario ID (e.g., "c_api_gateway_easy_009_bug_investigation_expert_01")
            context_file: Relative path from context_files (e.g., "EduGate_ScholarLink//src//components//validator.c")
            
        Returns:
            Full Path object to the code file
        """
        # Extract project directory from scenario ID
        project_dir = self._extract_project_dir_from_id(scenario_id)
        
        # Build base path: {generated_dir}/{project_dir}
        generated_dir = Path(self.config.data.generated_dir)
        project_path = generated_dir / project_dir
        
        # Normalize context_file path (replace // with /)
        normalized_context_file = context_file.replace('//', '/')
        
        # Build full path
        full_path = project_path / normalized_context_file
        
        return full_path
    
    def _create_tools(self) -> List:
        """Create tools for the agent to use"""
        
        if not _LANGCHAIN_AVAILABLE or _tool is None:
            return []
        
        @_tool
        def read_scenario_file(file_path: str) -> Dict[str, Any]:
            """Read a scenario JSON file and return its contents.
            
            Args:
                file_path: Path to the scenario JSON file
                
            Returns:
                Dictionary containing the scenario data
            """
            try:
                # Handle both absolute and relative paths
                path = Path(file_path)
                if not path.is_absolute():
                    # Try to find the file in common locations
                    scenarios_dir = Path(self.config.data.output_dir) / "scenarios"
                    path = scenarios_dir / path.name
                
                with open(path, 'r') as f:
                    scenario_data = json.load(f)
                return scenario_data
            except Exception as e:
                logger.error(f"Error reading scenario file {file_path}: {e}")
                return {"error": str(e)}
        
        @tool
        def read_code_file(scenario_id: str, context_file: str) -> Dict[str, Any]:
            """Read a code file referenced in a scenario's context_files.
            
            The file path is resolved using the scenario ID to find the project directory
            and the context_file path from the scenario's context_files array.
            
            Args:
                scenario_id: Scenario ID (e.g., "c_api_gateway_easy_009_bug_investigation_expert_01")
                context_file: Relative path from context_files (e.g., "EduGate_ScholarLink//src//components//validator.c")
                
            Returns:
                Dictionary with file content and metadata:
                {
                    "path": full_path,
                    "content": file_content,
                    "exists": True/False
                }
            """
            try:
                # Get full path to the code file
                full_path = self._get_code_file_path(scenario_id, context_file)
                
                if not full_path.exists():
                    return {
                        "path": str(full_path),
                        "exists": False,
                        "error": f"File not found: {full_path}"
                    }
                
                # Read file content
                with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                return {
                    "path": str(full_path),
                    "content": content,
                    "exists": True,
                    "size": len(content),
                    "lines": len(content.splitlines())
                }
            except Exception as e:
                logger.error(f"Error reading code file {context_file} for scenario {scenario_id}: {e}")
                return {
                    "path": str(context_file),
                    "exists": False,
                    "error": str(e)
                }
        
        @tool
        def read_scenario_context_files(scenario: Dict[str, Any], max_files: int = 10) -> Dict[str, Any]:
            """Read all context files for a scenario.
            
            Args:
                scenario: Scenario dictionary with 'id' and 'context_files' fields
                max_files: Maximum number of files to read (default: 10)
                
            Returns:
                Dictionary with file contents:
                {
                    "scenario_id": scenario_id,
                    "files": [
                        {"path": path, "content": content, "exists": True/False},
                        ...
                    ]
                }
            """
            scenario_id = scenario.get('id', '')
            context_files = scenario.get('context_files', [])
            
            if not scenario_id:
                return {"error": "Scenario ID is missing"}
            
            if not context_files:
                return {"error": "No context_files found in scenario"}
            
            # Limit number of files to read
            files_to_read = context_files[:max_files]
            
            file_contents = []
            for context_file in files_to_read:
                # Call the method directly to get file data
                try:
                    full_path = self._get_code_file_path(scenario_id, context_file)
                    
                    if not full_path.exists():
                        file_data = {
                            "path": str(full_path),
                            "exists": False,
                            "error": f"File not found: {full_path}"
                        }
                    else:
                        with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                            content = f.read()
                        file_data = {
                            "path": str(full_path),
                            "content": content,
                            "exists": True,
                            "size": len(content),
                            "lines": len(content.splitlines())
                        }
                except Exception as e:
                    file_data = {
                        "path": str(context_file),
                        "exists": False,
                        "error": str(e)
                    }
                
                file_contents.append({
                    "context_file": context_file,
                    **file_data
                })
            
            return {
                "scenario_id": scenario_id,
                "total_context_files": len(context_files),
                "files_read": len(file_contents),
                "files": file_contents
            }
        
        @tool
        def get_scenario_metadata(scenario: Dict[str, Any]) -> Dict[str, Any]:
            """Extract metadata from a scenario.
            
            Args:
                scenario: Scenario dictionary
                
            Returns:
                Dictionary with scenario metadata (id, difficulty, language, task_category, project_dir, context_files_count)
            """
            scenario_id = scenario.get('id', '')
            difficulty = scenario.get('difficulty', '').lower()
            task_category = scenario.get('task_category', '')
            context_files = scenario.get('context_files', [])
            
            # Extract language from scenario ID
            language = self._get_scenario_language(scenario)
            
            # Extract project directory
            project_dir = self._extract_project_dir_from_id(scenario_id)
            
            return {
                "id": scenario_id,
                "difficulty": difficulty,
                "language": language,
                "task_category": task_category,
                "project_dir": project_dir,
                "context_files_count": len(context_files),
                "context_files": context_files[:5]  # First 5 files as preview
            }
        
        @tool
        def filter_by_difficulty(scenarios: List[Dict[str, Any]], difficulty_levels: List[str]) -> List[Dict[str, Any]]:
            """Filter scenarios by difficulty level.
            
            Args:
                scenarios: List of scenario dictionaries
                difficulty_levels: List of difficulty levels to include (e.g., ['easy', 'medium'])
                
            Returns:
                Filtered list of scenarios
            """
            difficulty_levels_lower = [d.lower() for d in difficulty_levels]
            filtered = [
                s for s in scenarios 
                if s.get('difficulty', '').lower() in difficulty_levels_lower
            ]
            return filtered
        
        @tool
        def filter_by_language(scenarios: List[Dict[str, Any]], supported_languages: List[str]) -> List[Dict[str, Any]]:
            """Filter scenarios by programming language.
            
            Args:
                scenarios: List of scenario dictionaries
                supported_languages: List of supported languages to include
                
            Returns:
                Filtered list of scenarios
            """
            filtered = []
            for scenario in scenarios:
                scenario_language = self._get_scenario_language(scenario)
                if scenario_language in supported_languages:
                    filtered.append(scenario)
            return filtered
        
        return [read_scenario_file, read_code_file, read_scenario_context_files, get_scenario_metadata, filter_by_difficulty, filter_by_language]
    
    def _get_scenario_language(self, scenario: Dict[str, Any]) -> str:
        """Extract language from scenario ID"""
        scenario_id = scenario.get('id', '')
        if not scenario_id:
            return 'unknown'

        parts = scenario_id.split('_')
        if not parts:
            return 'unknown'
        
        language = parts[0].lower()

        language_mapping = {
            'c': 'c',
            'cpp': 'cpp', 
            'cs': 'csharp', 'csharp': 'csharp',
            'go': 'go',
            'java': 'java',
            'js': 'javascript', 'javascript': 'javascript',
            'php': 'php',
            'py': 'python', 'python': 'python',
            'rs': 'rust', 'rust': 'rust',
            'ts': 'typescript', 'typescript': 'typescript'
        }
        
        return language_mapping.get(language, language)
    
    def _filter_scenarios(self, scenarios: List[Dict[str, Any]], 
                         task_categories: Optional[List[str]], 
                         difficulty_levels: Optional[List[str]]) -> List[Dict[str, Any]]:
        """Filter scenarios based on criteria"""
        
        filtered = scenarios
        supported_languages = self.config.phase1.supported_languages
        
        # Filter by language if supported_languages is configured
        if supported_languages:
            filtered = [s for s in filtered if self._get_scenario_language(s) in supported_languages]
            logger.info(f"ðŸŒ Language filtering: {len(scenarios)} â†’ {len(filtered)} scenarios")
        
        if task_categories:
            filtered = [s for s in filtered if s.get('task_category') in task_categories]
        
        if difficulty_levels:
            difficulty_levels_lower = [d.lower() for d in difficulty_levels]
            filtered = [s for s in filtered if s.get('difficulty', '').lower() in difficulty_levels_lower]
        
        return filtered
    
    def filter_scenarios_from_files(
        self,
        scenarios_dir: Path,
        difficulty_levels: Optional[List[str]] = None,
        task_categories: Optional[List[str]] = None,
        use_llm_selection: bool = True
    ) -> List[Dict[str, Any]]:
        """
        Read scenarios from files and filter them using LLM-based selection
        
        Args:
            scenarios_dir: Directory containing scenario JSON files
            difficulty_levels: Optional list of difficulty levels to filter by
            task_categories: Optional list of task categories to filter by
            use_llm_selection: Whether to use LLM agent for intelligent selection
            
        Returns:
            List of filtered scenario dictionaries
        """
        # Load all scenarios from files
        all_scenarios = []
        scenario_files = list(scenarios_dir.glob("*.json"))
        
        logger.info(f"ðŸ“ Found {len(scenario_files)} scenario files in {scenarios_dir}")
        
        for scenario_file in scenario_files:
            try:
                with open(scenario_file, 'r') as f:
                    scenario_data = json.load(f)
                    # Each file contains a single scenario object
                    all_scenarios.append(scenario_data)
            except Exception as e:
                logger.error(f"Error loading scenario from {scenario_file}: {e}")
                continue
        
        if not all_scenarios:
            logger.warning("No scenarios found in scenario files!")
            return []
        
        logger.info(f"ðŸ“Š Loaded {len(all_scenarios)} scenarios")
        
        # Apply basic filtering first
        filtered_scenarios = self._filter_scenarios(
            all_scenarios,
            task_categories=task_categories,
            difficulty_levels=difficulty_levels
        )
        
        logger.info(f"ðŸ” After basic filtering: {len(all_scenarios)} â†’ {len(filtered_scenarios)} scenarios")
        
        # If LLM selection is enabled and agent is available, use agent to further refine selection
        if use_llm_selection and filtered_scenarios and self.agent_executor is not None:
            try:
                # Store scenarios for tool access
                self._scenarios_cache = filtered_scenarios
                
                # Prepare file paths for the agent to read
                scenario_file_paths = [str(f) for f in scenario_files[:len(filtered_scenarios)]]
                
                # Create agent input
                agent_input = f"""You need to analyze and filter scenarios from JSON files.

Filtering criteria:
- Difficulty levels: {difficulty_levels if difficulty_levels else 'all'}
- Supported languages: {self.config.phase1.supported_languages}
- Task categories: {task_categories if task_categories else 'all'}

Available scenario files:
{chr(10).join([f"- {path}" for path in scenario_file_paths[:20]])}

Your task:
1. Read the scenario files using read_scenario_file tool
2. Extract metadata from each scenario using get_scenario_metadata tool
3. Optionally read actual code files using read_code_file or read_scenario_context_files to analyze content
4. Apply filtering using filter_by_difficulty and filter_by_language tools
5. Select the most relevant scenarios based on the criteria

The scenario ID format is: {language}_{project_name}_{complexity}_{number}_{task_category}_{difficulty}_{instance}
Example: "c_api_gateway_easy_009_bug_investigation_expert_01"

To read code files, use:
- read_code_file(scenario_id, context_file_path) for a single file
- read_scenario_context_files(scenario) to read all context files for a scenario

Start by reading a few scenario files to understand their structure, then apply the appropriate filters."""
                
                # Run agent
                result = self.agent_executor.invoke({"input": agent_input})
                
                # The agent will use tools to filter scenarios
                # The filtered results are already applied through tool calls
                logger.info(f"ðŸ¤– LLM agent completed selection: {result.get('output', 'N/A')}")
                
                # Note: In a production implementation, you would parse the agent's tool calls
                # and extract the filtered scenarios. For now, we return the pre-filtered scenarios
                # as the agent's tool calls modify the internal state.
                
            except Exception as e:
                logger.error(f"Error in LLM-based selection: {e}")
                logger.info("Falling back to basic filtering")
                # Clean up cache
                if hasattr(self, '_scenarios_cache'):
                    delattr(self, '_scenarios_cache')
        elif use_llm_selection:
            if not _try_import_langchain():
                logger.warning("LLM-based selection requested but LangChain is not available. Using basic filtering only.")
        
        # Log difficulty distribution after filtering
        if filtered_scenarios:
            difficulty_counts = {}
            for s in filtered_scenarios:
                diff = s.get('difficulty', 'unknown').lower()
                difficulty_counts[diff] = difficulty_counts.get(diff, 0) + 1
            logger.info(f"ðŸ“Š Scenario difficulty distribution after filtering: {difficulty_counts}")
        
        return filtered_scenarios


def create_scenario_filter(config: Config, base_url: str = None, api_key: str = None, model: str = None) -> LoCoBenchScenarioFilter:
    """
    Factory function to create a scenario filter instance
    
    Args:
        config: LoCoBench configuration object
        base_url: Base URL for the OpenAI-compatible API (defaults to config.mcp_filter.base_url)
        api_key: API key for authentication (defaults to config.mcp_filter.api_key)
        model: Model name for the filter agent (defaults to config.mcp_filter.model)
        
    Returns:
        LoCoBenchScenarioFilter instance
    """
    return LoCoBenchScenarioFilter(config, base_url=base_url, api_key=api_key, model=model)
