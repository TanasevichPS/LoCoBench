# Анализ изменений в логике передачи контекста

## Проблема

**До изменений**: Длина промпта для эксперта была ~3-5к символов  
**После изменений**: Длина промпта для эксперта стала ~1M символов, потребовалась обрезка до 32к

## Что изменилось

### 1. Раньше (исходная версия LoCoBench)

**Логика передачи контекста:**
- В `scenario['context_files']` были **специально отобранные файлы** для задачи (обычно 3-10 файлов)
- Эти файлы передавались в ретривер как `context_files_content`
- Ретривер выбирал из них топ-5% или топ-K файлов по релевантности
- Итоговый промпт был компактным (~3-5к символов)

**Код (старая логика):**
```python
# В evaluator.py (старая версия)
context_obj = scenario.get('context_files')  # Dict с отобранными файлами
if isinstance(context_obj, dict):
    context_files_content = {
        path: content for path, content in context_obj.items()
    }
# Передавалось только содержимое scenario['context_files']
retrieved_context = retrieve_relevant(
    context_files_content,  # Только отобранные файлы!
    task_prompt_text,
    top_percent=0.05,  # Выбирает топ-5% из отобранных файлов
)
```

**Почему это работало хорошо:**
1. ✅ `scenario['context_files']` уже содержал **релевантные файлы**, отфильтрованные генератором сценариев
2. ✅ Ретривер работал с **небольшим набором** (3-10 файлов) и выбирал самые релевантные
3. ✅ Модель получала **компактный, но релевантный контекст**
4. ✅ Не было перегрузки контекста

### 2. После изменений (текущая версия)

**Логика передачи контекста:**
- Добавлена логика `should_load_all_files = difficulty in ['hard', 'expert']`
- Для hard/expert сценариев теперь загружаются **ВСЕ файлы проекта** через `include_all_project_files=True`
- Это может быть **100-1000+ файлов проекта** (весь кодбейз)
- Ретривер получает все эти файлы и пытается выбрать из них
- Но даже после ретривера остается огромный контекст (до 1M символов)

**Код (новая логика):**
```python
# В evaluator.py (текущая версия)
should_load_all_files = difficulty in ['hard', 'expert']  # ← НОВОЕ!

context_obj = scenario.get('context_files')
if isinstance(context_obj, dict):
    context_files_content = {
        path: content for path, content in context_obj.items()
    }
    # ← НОВОЕ: Для hard/expert загружаются ВСЕ файлы проекта
    if should_load_all_files and project_dir and project_dir.exists():
        all_project_files = load_context_files_from_scenario(
            scenario,
            project_dir=project_dir,
            include_all_project_files=True,  # ← Загружает ВСЕ файлы проекта!
        )
        context_files_content.update(all_project_files)  # ← Объединяет со всеми файлами

# Теперь передается весь проект + отобранные файлы
retrieved_context = retrieve_relevant(
    context_files_content,  # ВСЕ файлы проекта (100-1000+ файлов)!
    task_prompt_text,
    top_percent=0.05,  # Выбирает топ-5% из ВСЕХ файлов проекта
)
```

**Что происходит в `load_context_files_from_scenario`:**
```python
def load_context_files_from_scenario(..., include_all_project_files: bool = False):
    if include_all_project_files and project_dir and project_dir.exists():
        # ← Загружает ВСЕ файлы проекта через _collect_project_code_files
        return {
            file_info["path"]: file_info["content"]
            for file_info in _collect_project_code_files(project_dir)  # ← ВСЕ файлы!
        }
```

**Проблемы новой логики:**
1. ❌ Для эксперта загружается **весь проект** (может быть 500K-2M символов)
2. ❌ Ретривер выбирает топ-5% из **всего проекта**, но это все равно много файлов
3. ❌ Даже после ретривера остается огромный контекст (до 1M символов)
4. ❌ Пришлось добавить **тупую обрезку** до 32к символов (строки 2577-2667 в evaluator.py)
5. ❌ Обрезка происходит **после ретривера**, теряется релевантная информация

## Почему раньше результаты были не хуже?

### 1. Качество > Количество
- **Раньше**: Небольшой набор **релевантных файлов** (3-10 файлов)
- **Теперь**: Огромный набор файлов, из которого выбирается топ-5%

### 2. Эффективность ретривера
- **Раньше**: Ретривер работал с **маленьким, но качественным** набором файлов
- **Теперь**: Ретривер работает с **огромным набором**, что может снизить качество ранжирования

### 3. Информационная плотность
- **Раньше**: Каждый файл в контексте был **высоко релевантен** задаче
- **Теперь**: Много файлов с **низкой релевантностью**, которые попадают в топ-5% просто из-за объема

### 4. Ограничения модели
- **Раньше**: Модель получала **компактный, но полный** контекст
- **Теперь**: Модель получает **обрезанный контекст** (32к), который может не содержать ключевые части

### 5. Генератор сценариев уже делал фильтрацию
- **Раньше**: `scenario['context_files']` уже содержал файлы, **отобранные генератором** на основе задачи
- **Теперь**: Игнорируется работа генератора, загружается весь проект

## Рекомендации

### Вариант 1: Вернуться к старой логике (рекомендуется)
```python
# Убрать should_load_all_files для ретривера
# Использовать только scenario['context_files']
context_files_content = {
    path: content for path, content in scenario.get('context_files', {}).items()
}
retrieved_context = retrieve_relevant(
    context_files_content,  # Только отобранные файлы
    task_prompt_text,
    ...
)
```

### Вариант 2: Улучшить ретривер
- Увеличить `top_percent` для hard/expert (например, 0.10 вместо 0.05)
- Улучшить ранжирование для больших наборов файлов
- Использовать более агрессивную фильтрацию

### Вариант 3: Гибридный подход
- Для easy/medium: использовать только `scenario['context_files']`
- Для hard/expert: использовать весь проект, но с улучшенным ретривером
- Увеличить `max_context_tokens` для ретривера (например, до 100k)

## Вывод

**Раньше работало лучше**, потому что:
1. Использовались **уже отфильтрованные файлы** из `scenario['context_files']`
2. Ретривер работал с **компактным, но релевантным** набором
3. Модель получала **полный контекст** без обрезки
4. **Качество > Количество**

**Теперь хуже**, потому что:
1. Загружается **весь проект** для hard/expert
2. Ретривер перегружен **огромным набором** файлов
3. Модель получает **обрезанный контекст** (32к)
4. **Количество > Качество** (но с обрезкой)
